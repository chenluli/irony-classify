{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from json import JSONDecoder\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "trainA_file = os.path.join(data_folder, 'trainA.json')\n",
    "trainB_file = os.path.join(data_folder, 'trainB.json')\n",
    "test_file = os.path.join(data_folder, 'test.json')\n",
    "\n",
    "train_feature_f = os.path.join(data_folder, 'task3_train_feature.txt')\n",
    "test_feature_f = os.path.join(data_folder, 'task3_test_feature.txt')\n",
    "\n",
    "word2idx_f = os.path.join(data_folder, 'word2idx.json')\n",
    "pos2idx_f = os.path.join(data_folder, 'pos2idx.json')\n",
    "word_embeds_f = os.path.join(data_folder, 'word_embedding.npy')\n",
    "pos_embeds_f = os.path.join(data_folder, 'pos_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        dataList=data['data']\n",
    "    return dataList\n",
    "\n",
    "def load_seq_feats(filename):\n",
    "    with open(filename,'r')as f:\n",
    "        test_feature=f.read()\n",
    "    test_feature=JSONDecoder().decode(test_feature)\n",
    "    return test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 3450 #valud: 384 #test: 784\n"
     ]
    }
   ],
   "source": [
    "trainA = load_data(trainA_file)[:3450]\n",
    "validA = load_data(trainA_file)[3450:]\n",
    "trainB = load_data(trainB_file)[:3450]\n",
    "validB = load_data(trainB_file)[3450:]\n",
    "test = load_data(test_file)\n",
    "print(\"#train:\", len(trainA),\"#valud:\", len(validA),\"#test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = load_seq_feats(train_feature_f)\n",
    "test_feature = load_seq_feats(test_feature_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load word and pos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(fname):\n",
    "    with open(fname, 'r') as file:\n",
    "        dictionary = json.load(file)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 12656\n"
     ]
    }
   ],
   "source": [
    "word2idx = load_dict(word2idx_f)\n",
    "pos2idx = load_dict(pos2idx_f)\n",
    "vocab_size = len(word2idx)\n",
    "print(\"vocab size:\", vocab_size)\n",
    "\n",
    "word_embedding = np.load(word_embeds_f)\n",
    "pos_embedding = np.load(pos_embeds_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12656, 700) (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(word_embedding.shape, pos_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Encoding  \n",
    "$P E_{2 i}(p)=\\sin \\left(p / 10000^{2 i / d_{model}}\\right)$   \n",
    "$P E_{2 i+1}(p)=\\cos \\left(p / 10000^{2 i / d_{model}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回的是x+pe\n",
    "def positional_enc(x, dim_model, max_len=5000):\n",
    "    base = 10000\n",
    "    sentence_len = x.size(1)\n",
    "    pe_vec = torch.zeros(max_len, dim_model)\n",
    "    p = torch.arange(0., max_len).unsqueeze(1)\n",
    "    frac = torch.exp(torch.arange(0., dim_model, 2) * -(math.log(10000.0) / dim_model)) \n",
    "    pe_vec[:,0::2] = torch.sin(p)\n",
    "    pe_vec[:,1::2] = torch.cos(p)\n",
    "    pe_vec = pe_vec.unsqueeze(0)\n",
    "    return x.float() + pe_vec[:,:sentence_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention\n",
    "scaled dot product attention:\n",
    " $\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None, dropout=None):\n",
    "    dim_key = query.size(-1)\n",
    "    attn = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(dim_key)\n",
    "    if mask is not None:\n",
    "        attn = scores.masked_fill(mask == 0, -1e9)\n",
    "    attn_weights = F.softmax(attn, dim = -1)\n",
    "    if dropout is not None:\n",
    "        attn_weights = dropout(attn_weights)\n",
    "    return torch.matmul(attn_weights, value), attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self attention: K=V=Q  \n",
    "each word in the sentence needs to undergo Attention computation, to capture the internal structure of the sentence\n",
    "\n",
    "Multi-head Attention: query, key, and value first go through a linear transformation and then enters into Scaled-Dot Attention. Here, the attention is calculated h times, which allows the model to learn relevant information in different representative child spaces.  \n",
    "When #head=1, it becomes a original self-attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, num_heads, dim_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        # make sure input word embedding dimension divides by the number of desired heads\n",
    "        assert dim_model % num_heads == 0\n",
    "        # assume dim of key,query,values are equal\n",
    "        self.dim_qkv = dim_model // num_heads\n",
    "        \n",
    "        self.dim_model = dim_model\n",
    "        self.num_h = num_heads\n",
    "        self.w_q = nn.Linear(dim_model, dim_model) # self.w_qs = nn.Linear(d_model, n_head * d_k) \n",
    "        self.w_k = nn.Linear(dim_model, dim_model) \n",
    "        self.w_v = nn.Linear(dim_model, dim_model)\n",
    "        \n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            \n",
    "        n_batch = query.size(0)\n",
    "#         residual = query\n",
    "        \n",
    "        # linear projections: dim_model => num_h x dim_k \n",
    "        query = self.w_q(query).view(n_batch, -1, self.num_h, self.dim_qkv)\n",
    "        key = self.w_k(key).view(n_batch, -1, self.num_h, self.dim_qkv)\n",
    "        value = self.w_v(value).view(n_batch, -1, self.num_h, self.dim_qkv)\n",
    "        \n",
    "        # Apply attention on all the projected vectors in batch \n",
    "        x, self.attn = scaled_dot_product_attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # Concat(head1, ..., headh) \n",
    "        x = x.transpose(1, 2).contiguous().view(n_batch, -1, self.num_h * self.dim_qkv)\n",
    "        \n",
    "        x = nn.Linear(dim_model, dim_model, bias=False)(x)\n",
    "#         x = self.layer_norm(x + residual)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position-wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu # bert uses gelu instead\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add & Norm\n",
    "`Residual connection`是对于较为深层的神经网络有比较好的作用，比如网络层很深时，数值的传播随着weight不断的减弱，`Residual connection`是从输入的部分，连到它输出层的部分，把输入的信息原封不动copy到输出的部分，减少信息的损失。\n",
    "`layer-normalization`这种归一化层是为了防止在某些层中由于某些位置过大或者过小导致数值过大或过小，对神经网络梯度回传时有训练的问题，保证训练的稳定性。基本在每个子网络后面都要加上`layer-normalization`、加上`Residual connection`，加上这两个部分能够使深层神经网络训练更加顺利。  \n",
    "(本实验中也许不需要)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, size, dropout, eps=1e-6):\n",
    "        super(AddNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(size))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(size))\n",
    "        self.eps = eps\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        x = x.float()\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        norm = self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "        return x + self.dropout(sublayer(norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder\n",
    "self-attention layers: all of the keys, values and queries come from the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一层Encoder: self-atten --> add&norm --> feed-forward --> add&norm\n",
    "# 浅层网络可以去掉add&norm层？\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, attention, feed_forward, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.feed_forward = feed_forward\n",
    "        self.self_atten = attention\n",
    "        self.add_norm_1 = AddNorm(size, dropout)\n",
    "        self.add_norm_2 = AddNorm(size, dropout)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        output = self.add_norm_1(x, lambda x: self.self_atten(x, x, x, mask))\n",
    "        output = self.add_norm_2(output, self.feed_forward)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)]) # clone the layer for N times\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMax(nn.Module):\n",
    "    def __init__(self,n_input,n_out):\n",
    "        super(SoftMax,self).__init__()\n",
    "        self.fc = nn.Linear(n_input,n_out)\n",
    "        self.softmax = nn.LogSoftmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        y = self.softmax(x)\n",
    "        return F.softmax(y,dim=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single task\n",
    "# embeding --> encoder --> linear --> softmax\n",
    "class SelfAttenClassifier(nn.Module):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        super(SelfAttenClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, input_embeds):\n",
    "        batch_size = input_embeds.size(1)\n",
    "        encoder_out = self.encoder(input_embeds)\n",
    "        # Simply average the final sequence position representations to create a fixed size \"sentence representation\".\n",
    "#         sentence_representation = tf.reduce_mean(encoder_output, axis=1)    # [batch_size, model_dim]\n",
    "        feats = encoder_out.sum(dim=1)\n",
    "#         print(encoder_out.size(), feats.size())\n",
    "        outputs = self.classifier(feats)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TODO concatenate sentence embedding before classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO multi-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize sequences as inputs \n",
    "def seq_to_tensor(raw_sample,dim_model=728):\n",
    "    seq_embed = torch.tensor([np.concatenate([word_embedding[word2idx[w]],pos_embedding[pos2idx[raw_sample[\"pos\"][i]]]]) \n",
    "                       for i,w in enumerate(raw_sample[\"word\"])])\n",
    "    return seq_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IronyDataset(Dataset):\n",
    "    def __init__(self, raw_data, transform=None):\n",
    "        self.data = raw_data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        label = self.data[index][\"label\"]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IronyDataset(trainA, seq_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and pading sequence batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic padding: seqeuences are padded to the maximum length of mini-batch sequences\n",
    "def collate_fn(batch):\n",
    "    sorted_batch = sorted(batch, key=lambda x: x[0].size(0), reverse=True)\n",
    "    sequences = [x[0] for x in sorted_batch]\n",
    "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.LongTensor([len(x) for x in sequences])\n",
    "    labels = torch.LongTensor(list(map(lambda x: x[1], sorted_batch)))\n",
    "    return sequences_padded, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(model,loader):\n",
    "    model.eval()\n",
    "    num_corrects = 0\n",
    "    for data in loader:\n",
    "        x, y, lengths = batch\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "#         print(torch.max(pred, 1)[1].view(y.size()).data)\n",
    "#         print(y.data)\n",
    "        num_corrects += (torch.max(pred, 1)[1].view(y.size()).data == y.data).sum()\n",
    "    return num_corrects.item() / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_acc(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4271186440677966"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1512).item()/3540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x, y, lengths = batch\n",
    "        optimizer.zero_grad()\n",
    "        # !!TOCHECK add positional encoding here or other place??\n",
    "        x = positional_enc(x, dim_model)\n",
    "        out = model(x)\n",
    "        loss = loss_func(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_layers = 2\n",
    "dim_model=728 # equal to the dim of word embeddings\n",
    "num_heads=8 # dim_model % num_heads == 0\n",
    "d_ff=2912\n",
    "dropout=0.1\n",
    "\n",
    "# c = copy.deepcopy\n",
    "attn_layer = MultiHeadedAttention(num_heads, dim_model)\n",
    "ff_layer = PositionwiseFeedForward(dim_model, d_ff, dropout)\n",
    "\n",
    "num_class = 2\n",
    "model = SelfAttenClassifier(\n",
    "    encoder = Encoder(EncoderLayer(dim_model,attn_layer,ff_layer),num_encoder_layers),\n",
    "    classifier = SoftMax(dim_model,num_class),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Acc: 0.00000000, Duration: 181.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-b0c80f2f7f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-299-e6e24992f748>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_func, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/env3.5/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/env3.5/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c95c7563d5b1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b4f3bdfb1449>\u001b[0m in \u001b[0;36mseq_to_tensor\u001b[0;34m(raw_sample, dim_model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m728\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     seq_embed = torch.tensor([np.concatenate([word_embedding[word2idx[w]],pos_embedding[pos2idx[raw_sample[\"pos\"][i]]]]) \n\u001b[0;32m----> 4\u001b[0;31m                        for i,w in enumerate(raw_sample[\"word\"])])\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "import time\n",
    "loss_function = F.nll_loss \n",
    "\n",
    "time_p, tr_acc_array, ts_acc, loss_p = [], [], [], []\n",
    "epochs = 20\n",
    "# running epoches\n",
    "for epoch in range(1, epochs + 1):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_start = time.perf_counter()\n",
    "\n",
    "        train_loss = train(model, train_loader, loss_function,optimizer)\n",
    "        train_acc = binary_acc(model, train_loader)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_end = time.perf_counter()\n",
    "        time_p.append(t_end)\n",
    "        loss_p.append(train_loss)\n",
    "        tr_acc_array.append(train_acc)\n",
    "\n",
    "        print('Epoch: {:03d}, Acc: {:.8f}, Duration: {:.2f}'.format(\n",
    "            epoch, train_acc, t_end - t_start))\n",
    "\n",
    "# save model params\n",
    "torch.save(model.state_dict(), 'taskA_transformer_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "color = cm.viridis(0.7)\n",
    "f, ax = plt.subplots(1,1)\n",
    "epoches = [i for i in range(len(loss_p))]\n",
    "ax.plot(epoches, loss_p, color=color)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('epoches')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TaskB\n",
    "Since the data for taskB is imbalanced, add a weight for the loss of each sample according to its label during the training time:  \n",
    "{label:weight}={0.0: 1.9907674552798615, 1.0: 2.7555910543130993, 2.0:12.23404255319149, 3.0: 18.852459016393443}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    for batch in loader:\n",
    "        x, y = batch.text, batch.label - 1\n",
    "        outputs,_ = model(x, x_l)\n",
    "        total_acc += binary_accuracy(outputs.view(-1), y.float()).item()\n",
    "    return total_acc / len(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_heatmap(model, dialog_vocab, candidate_vocab, memory, query, label=None):\n",
    "    \n",
    "    pred, attn = model(Variable(memory), Variable(query))\n",
    "    \n",
    "    attn = attn.squeeze(0).data.numpy()\n",
    "    \n",
    "    y_labels = []\n",
    "    pad = dialog_vocab.word_to_index('<pad>')\n",
    "    for row in memory.squeeze(0).numpy():\n",
    "        row = row.tolist()\n",
    "        end = len(row)\n",
    "        if pad in row:\n",
    "            end = row.index(pad)\n",
    "        y_labels.append(vec2sent(dialog_vocab, row[2:end]))\n",
    "    \n",
    "    ax = plt.axes()\n",
    "    ax.set_title('Attention Weights per Memory Hops')\n",
    "    ax = sns.heatmap(attn, linewidths=.5, square=True, yticklabels=y_labels, ax=ax, cmap=sns.color_palette(\"Blues\"))\n",
    "    ax.set(xlabel='Hops', ylabel='Memory Contents')\n",
    "    plt.show()\n",
    "    \n",
    "    if label:\n",
    "        print('True label: ', candidate_vocab.index_to_word(label))\n",
    "        print('Prediction: ', candidate_vocab.index_to_word(torch.max(pred.data, 1)[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全self-attention层可能存在的问题：\n",
    "- only capture the inner structure of a sentence, the relations between sentence parts and classification are not captured directly.\n",
    "- position information is not sufficiently modeled.\n",
    "\n",
    "因此经常self-attention层会和RNN/LSTM结合使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "wirte predicted labels for test data:(one sample a line): label+\\t+orinignal word list\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks)\n",
    "- [Multi-head Self Attention for Text Classification](https://www.kaggle.com/fareise/multi-head-self-attention-for-text-classification)\n",
    "\n",
    "--代码参考--\n",
    "- [BERT-pytorch](https://github.com/codertimo/BERT-pytorch]\n",
    "- [Variable-sized mini-batches and why PyTorch is good for your health](https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "env3.5",
   "language": "python",
   "name": "env3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
